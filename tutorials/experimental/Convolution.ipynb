{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import tenseal as ts\n",
    "import numpy as np\n",
    "from skimage.util.shape import view_as_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def almost_equal(vec1, vec2, m_pow_ten):\n",
    "    if len(vec1) != len(vec2):\n",
    "        return False\n",
    "\n",
    "    upper_bound = pow(10, -m_pow_ten)\n",
    "    for v1, v2 in zip(vec1, vec2):\n",
    "        if abs(v1 - v2) > upper_bound:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Torch 2d convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_conv_2d(x, kernel, stride):\n",
    "    return torch.nn.functional.conv2d(\n",
    "        input=x, weight=kernel, stride=stride, padding=0, dilation=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 13\u001b[0m\n\u001b[1;32m      6\u001b[0m stride \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[39m# # generated incremeneted values: 1, 2, ..., n^2\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[39m# x = np.arange(1, x_size ** 2 + 1).reshape(x_size, x_size)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[39m# kernel = np.arange(1, k_size ** 2 + 1).reshape(k_size, k_size)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \n\u001b[1;32m     12\u001b[0m \u001b[39m# generated random values\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m x \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrandn(x_size, \u001b[39m1\u001b[39m)\n\u001b[1;32m     14\u001b[0m kernel \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrandn(k_size, \u001b[39m1\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39minput\u001b[39m\u001b[39m\"\u001b[39m, x\u001b[39m.\u001b[39mshape)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# input image dimension n * n\n",
    "x_size = 3\n",
    "# kernel dimension n * n\n",
    "k_size = 2\n",
    "# stride\n",
    "stride = 1\n",
    "\n",
    "# # generated incremeneted values: 1, 2, ..., n^2\n",
    "# x = np.arange(1, x_size ** 2 + 1).reshape(x_size, x_size)\n",
    "# kernel = np.arange(1, k_size ** 2 + 1).reshape(k_size, k_size)\n",
    "\n",
    "# generated random values\n",
    "x = np.random.randint(0, 10, size=(x_size, 1))\n",
    "kernel = np.random.randint(0, 10, size=(k_size, 1))\n",
    "\n",
    "print(\"input\", x.shape)\n",
    "print(x)\n",
    "print(\"kernel\", kernel.shape)\n",
    "print(kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TenSEAL context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TenSEAL context\n",
    "context = ts.context(\n",
    "    ts.SCHEME_TYPE.CKKS, 8192, coeff_mod_bit_sizes=[60, 40, 40, 60]\n",
    ")\n",
    "# set the scale\n",
    "context.global_scale = pow(2, 40)\n",
    "# generated galois keys in order to do rotation on ciphertext vectors\n",
    "context.generate_galois_keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each convolution layer, a communication between the client and server is required. The server send the ciphertext (encrypted vector) to the client which is the input of the next convolution layer, in order to decrypt it and apply im2col (Image Block to Column) on the that input.\n",
    "\n",
    "After that the client encode and encrypt the input matrix in a vertical scan (column-major) and send it back to the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "x_enc, windows_nb = ts.im2col_encoding(context, x, kernel.shape[0], kernel.shape[1], stride)\n",
    "\n",
    "print(\"windows number: \", windows_nb)\n",
    "print(\"ckksvector size: \", x_enc.size())\n",
    "\n",
    "y_enc = x_enc.conv2d_im2col(kernel.tolist(), windows_nb)\n",
    "\n",
    "print(y_enc.size())\n",
    "y_plain = y_enc.decrypt()\n",
    "\n",
    "print(\"y_enc\")\n",
    "print(y_plain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the result to torch conv2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_toch\n",
      "[ -54.58763     87.4021      47.199284    34.291573  -111.8195\n",
      "    6.2725477  100.97608   -106.42866    -31.869497    43.06913\n",
      "  110.91937     69.30648     76.14888    177.25304    105.908844\n",
      "  -21.30675     12.912507   -27.024754   -16.25838    -47.6781\n",
      "   81.64753    137.79376     91.30269    -94.195076  -196.98035\n",
      " -125.99463     42.880825  -131.80736    -78.094765    59.072765\n",
      "   69.54799    -77.53858    -67.61382    -79.19424    -82.42037\n",
      "  -55.323532    21.918015    81.582664    59.006775   -86.694984\n",
      "  -50.26876    -30.892807     9.307717  -133.45465    -92.55416\n",
      "  -23.359943    23.213211    -2.048564   -80.353806   -11.300457\n",
      "    3.8368444   36.394527    -8.637391     5.187211    44.294132\n",
      "   49.788925    35.600857   -23.631056    46.156494   -38.97396\n",
      "   56.187077    64.65246    -97.72869   -177.6504     -57.25484\n",
      "    8.721375    81.09992     31.083414     3.267823   -94.50235\n",
      " -157.55186      1.2791833  -48.5475    -114.12285     75.05805\n",
      "   54.170834    12.75259     16.23377     30.496946    -3.7115242\n",
      "  -63.751278    -4.5667987   90.79772    107.44124    -13.531111\n",
      " -116.08061    -67.2854      21.867352   -38.709564   -12.188522\n",
      "  101.4467      88.34729     37.311665    68.465225   -45.460632\n",
      "   56.403862   -64.905716    77.805244    76.0576     -68.618286\n",
      " -107.10601    -76.27609   -116.62796    -69.185616   -24.958601\n",
      "  -62.216244    53.728466    85.32235    167.48672     80.00436\n",
      "  -86.65235    -35.641163    -1.7878611  105.62036    -27.179909\n",
      "   -9.526508   -23.547125   -28.438509   -26.990805  -100.741714\n",
      "    8.86168    162.42456     88.68245      2.7611802    3.09983\n",
      "    5.908607   -41.871803    49.46887  ]\n"
     ]
    }
   ],
   "source": [
    "y_torch = torch_conv_2d(\n",
    "    torch.from_numpy(x.astype(\"float32\")).unsqueeze(0).unsqueeze(0),\n",
    "    torch.from_numpy(kernel.astype(\"float32\")).unsqueeze(0).unsqueeze(0),\n",
    "    stride\n",
    ")\n",
    "y_torch = y_torch.flatten().numpy()\n",
    "print(\"y_toch\")\n",
    "print(y_torch)\n",
    "\n",
    "assert almost_equal(y_plain, y_torch, 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "03216ab790e361277c895e5cb061fe3497b004a28cacb7cef2f0faadd28f614b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
